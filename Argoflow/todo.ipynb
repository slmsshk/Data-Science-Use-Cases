{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Core Setup**\n",
    "- Create images ✅\n",
    "- Create Container ✅\n",
    "- Add volume to container ✅\n",
    "- Host it on Kubernetes ✅\n",
    "- Create different kinds of pods\n",
    "- Implement microservices\n",
    "- Implement service mesh (e.g., Istio, Linkerd)\n",
    "- Implement caching (e.g., Redis)\n",
    "\n",
    "### **Scalability and Performance**\n",
    "- Practice scaling\n",
    "- Implement autoscaling (Kubernetes' autoscaling features)\n",
    "- Optimize Docker images (minimize size and build time)\n",
    "\n",
    "### **Security and Compliance**\n",
    "- Secure your containers (image scanning, runtime security)\n",
    "- Set up API gateway (e.g., Kong, NGINX)\n",
    "- Use environment variables (Kubernetes Secrets, etc.)\n",
    "\n",
    "### **Monitoring and Logging**\n",
    "- Monitoring (tools like Prometheus, Grafana)\n",
    "- Setup logging (ELK stack, Fluentd)\n",
    "\n",
    "### **Continuous Integration/Continuous Deployment (CI/CD)**\n",
    "- Setup CI/CD (GitHub Actions, Jenkins, etc.) ✅\n",
    "- Implement feature flags (e.g., LaunchDarkly)\n",
    "\n",
    "### **Advanced Tools and Infrastructure**\n",
    "- Load balancer, etcd\n",
    "- ArgoCD, Helm\n",
    "- Set up a backup and recovery strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def hello():\n",
    "    for i in range(10):\n",
    "        inp = await input('Enter  your name')\n",
    "        print('hi')\n",
    "\n",
    "hello()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = pipeline(\"text-generation\", model=\"bigcode/starcoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5Model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = T5Model.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    ").input_ids  # Batch size 1\n",
    "decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "\n",
    "# preprocess: Prepend decoder_input_ids with start token which is pad token for T5Model.\n",
    "# This is not needed for torch's T5ForConditionalGeneration as it does this internally using labels arg.\n",
    "decoder_input_ids = model._shift_right(decoder_input_ids)\n",
    "\n",
    "# forward pass\n",
    "outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "generated_text = tokenizer.decode(torch.argmax(last_hidden_states, dim=-1)[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
